{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bNChjE0dyou"
      },
      "outputs": [],
      "source": [
        "#importing Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import os, re, time, json\n",
        "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0l54sPUh23Dz"
      },
      "source": [
        "## KNN (It will take too much time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zx8FuPw9IygG"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/nholmber/google-colab-cs231n.git\n",
        "%cd google-colab-cs231n/assignment1\n",
        "!pip install imageio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGGT6Nmc204z"
      },
      "outputs": [],
      "source": [
        "# Run some setup code for this notebook.\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
        "# rather than in a new window.\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "# Some more magic so that the notebook will reload external python modules;\n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# Define function for inspecting the source code of a function\n",
        "import inspect\n",
        "from pygments import highlight\n",
        "from pygments.lexers import PythonLexer\n",
        "from pygments.formatters import Terminal256Formatter\n",
        "\n",
        "def pretty_print(func):\n",
        "  source_code = inspect.getsourcelines(func)[0]\n",
        "  for line in source_code:\n",
        "    print(highlight(line.strip('\\n'), PythonLexer(), Terminal256Formatter()), end='')\n",
        "  print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUOIlseseUL4"
      },
      "outputs": [],
      "source": [
        "#Loading dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6MG2uIDedPy"
      },
      "outputs": [],
      "source": [
        "# #visulazation\n",
        "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "num_classes = len(classes)\n",
        "samples_per_class = 7\n",
        "for y, cls in enumerate(classes):\n",
        "    idxs = np.flatnonzero(y_train == y)\n",
        "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
        "    for i, idx in enumerate(idxs):\n",
        "        plt_idx = i * num_classes + y + 1\n",
        "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
        "        plt.imshow(x_train[idx].astype('uint8'))\n",
        "        plt.axis('off')\n",
        "        if i == 0:\n",
        "            plt.title(cls)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1Jz-nLK3ZMx"
      },
      "outputs": [],
      "source": [
        "from cs231n.classifiers import KNearestNeighbor\n",
        "# Create a kNN classifier instance. \n",
        "# Remember that training a kNN classifier is a noop: \n",
        "# the Classifier simply remembers the data and does no further processing \n",
        "classifier = KNearestNeighbor()\n",
        "classifier.train(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRDThDR14DUu"
      },
      "outputs": [],
      "source": [
        "# Open cs231n/classifiers/k_nearest_neighbor.py and implement\n",
        "# compute_distances_two_loops.\n",
        "# Print out implementation\n",
        "pretty_print(classifier.compute_distances_two_loops)\n",
        "\n",
        "# Test your implementation:\n",
        "dists = classifier.compute_distances_two_loops(x_test)\n",
        "print(dists.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRZOW9ek4DR2"
      },
      "outputs": [],
      "source": [
        "plt.imshow(dists, interpolation='none')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqgblV5j4DH3"
      },
      "outputs": [],
      "source": [
        "# Now implement the function predict_labels and run the code below:\n",
        "# We use k = 1 (which is Nearest Neighbor).\n",
        "y_test_pred = classifier.predict_labels(dists, k=1)\n",
        "\n",
        "# Compute and print the fraction of correctly predicted examples\n",
        "num_correct = np.sum(y_test_pred == y_test)\n",
        "accuracy = float(num_correct) / num_test\n",
        "print('Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Eb3Du4-4TmN"
      },
      "outputs": [],
      "source": [
        "y_test_pred = classifier.predict_labels(dists, k=5)\n",
        "num_correct = np.sum(y_test_pred == y_test)\n",
        "accuracy = float(num_correct) / num_test\n",
        "print('Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbxRXzjm4ifc"
      },
      "source": [
        "### Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giojZNYm4X1u"
      },
      "outputs": [],
      "source": [
        "num_folds = 5\n",
        "k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]\n",
        "\n",
        "# Check that training set can be equally divided into num_folds portions\n",
        "if num_training/num_folds % num_folds != 0.0:\n",
        "    raise ValueError('Number of training examples not evenly divisible by number of folds.')\n",
        "\n",
        "# Split training set into num_folds lists\n",
        "X_train_folds = np.split(X_train, num_folds)\n",
        "y_train_folds = np.split(y_train, num_folds)\n",
        "\n",
        "# A dictionary holding the accuracies for different values of k that we find\n",
        "# when running cross-validation. After running cross-validation,\n",
        "# k_to_accuracies[k] should be a list of length num_folds giving the different\n",
        "# accuracy values that we found when using that value of k.\n",
        "k_to_accuracies = {}\n",
        "\n",
        "# Perform k-fold cross validation to find the best value of k\n",
        "# Loop over num_folds in outer loop to reuse computed distances for all values of k\n",
        "for k in k_choices:\n",
        "    k_to_accuracies[k] = []\n",
        "    \n",
        "for idx in range(num_folds):\n",
        "    # Use bin with index idx as validation set, rest as training set \n",
        "    X_train_set = np.concatenate((*X_train_folds[:idx], *X_train_folds[idx+1:]), axis=0)\n",
        "    y_train_set = np.concatenate((*y_train_folds[:idx], *y_train_folds[idx+1:]), axis=0)\n",
        "    X_validation_set = X_train_folds[idx]\n",
        "    y_validation_set = y_train_folds[idx]   \n",
        "    num_validation_set = X_validation_set.shape[0]\n",
        "    # Train kNN classifier\n",
        "    classifier = KNearestNeighbor()\n",
        "    classifier.train(X_train_set, y_train_set)\n",
        "    # Compute distances\n",
        "    dists_validate = classifier.compute_distances_no_loops(X_validation_set)\n",
        "    for k in k_choices:\n",
        "        # Predict labels for validation set\n",
        "        y_validation_pred = classifier.predict_labels(dists_validate, k=k)\n",
        "        # Check accuracy\n",
        "        accuracy = (float(np.sum(np.equal(y_validation_pred, y_validation_set)))/num_validation_set)\n",
        "        k_to_accuracies[k].append(accuracy)\n",
        "\n",
        "# Print out the computed accuracies\n",
        "for k in sorted(k_to_accuracies):\n",
        "    for accuracy in k_to_accuracies[k]:\n",
        "        print('k = %d, accuracy = %f' % (k, accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H05oQM6n4qgc"
      },
      "outputs": [],
      "source": [
        "# plot the raw observations\n",
        "for k in k_choices:\n",
        "    accuracies = k_to_accuracies[k]\n",
        "    print('k = %d, average accuracy = %f' % (k, np.average(accuracies)))\n",
        "    plt.scatter([k] * len(accuracies), accuracies)\n",
        "\n",
        "# plot the trend line with error bars that correspond to standard deviation\n",
        "accuracies_mean = np.array([np.mean(v) for k,v in sorted(k_to_accuracies.items())])\n",
        "accuracies_std = np.array([np.std(v) for k,v in sorted(k_to_accuracies.items())])\n",
        "plt.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)\n",
        "plt.title('Cross-validation on k')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Cross-validation accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0UlpqrX4uah"
      },
      "outputs": [],
      "source": [
        "# Based on the cross-validation results above, choose the best value for k,   \n",
        "# retrain the classifier using all the training data, and test it on the test\n",
        "# data. You should be able to get above 28% accuracy on the test data.\n",
        "best_k = 10\n",
        "\n",
        "classifier = KNearestNeighbor()\n",
        "classifier.train(X_train, y_train)\n",
        "y_test_pred = classifier.predict(X_test, k=best_k)\n",
        "\n",
        "# Compute and display the accuracy\n",
        "num_correct = np.sum(y_test_pred == y_test)\n",
        "accuracy = float(num_correct) / num_test\n",
        "print('Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GyVcZIf5O1r"
      },
      "source": [
        "## Non Linear SVM "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jK1v1dKD60Cq"
      },
      "outputs": [],
      "source": [
        "# Load the CIFAR10 dataset\n",
        "from keras.datasets import cifar10\n",
        "# baseDir = os.path.dirname(os.path.abspath('__file__')) + '/'\n",
        "classesName = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "(xTrain, yTrain), (xTest, yTest) = cifar10.load_data()\n",
        "xVal = xTrain[49000:, :].astype(np.float)\n",
        "yVal = np.squeeze(yTrain[49000:, :])\n",
        "xTrain = xTrain[:49000, :].astype(np.float)\n",
        "yTrain = np.squeeze(yTrain[:49000, :])\n",
        "yTest = np.squeeze(yTest)\n",
        "xTest = xTest.astype(np.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_URvU12R66zV"
      },
      "outputs": [],
      "source": [
        "#Reshaping Data into a Vector and Normalizing it (-1 to 1)\n",
        "print(xTrain.shape)\n",
        "print(yTrain.shape)\n",
        "xTrain = np.reshape(xTrain, (xTrain.shape[0], -1)) # The -1 means that the corresponding dimension is calculated from the other given dimensions.\n",
        "xVal = np.reshape(xVal, (xVal.shape[0], -1))\n",
        "xTest = np.reshape(xTest, (xTest.shape[0], -1))\n",
        "print(xTrain.shape) \n",
        "print(xTrain[0])\n",
        "\n",
        "#Normalize \n",
        "xTrain=((xTrain/255)*2)-1 \n",
        "print(xTrain.shape)\n",
        "print(xTrain[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHFn3ebq7Bo2"
      },
      "outputs": [],
      "source": [
        "#Choosing a smaller dataset\n",
        "xTrain=xTrain[:3000,:]\n",
        "yTrain=yTrain[:3000]\n",
        "print(yTrain)\n",
        "print(xTrain.shape)\n",
        "print(yTrain.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbvQLtEZLm0A"
      },
      "source": [
        "### SVM Polynomial Kernal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-s1T4gJt5lAd"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "acc_train_svm_poly = []\n",
        "acc_test_svm_poly = []\n",
        "\n",
        "def svm_polynomial(c):\n",
        "\n",
        "    svc_polynomial = svm.SVC(probability = False, kernel = 'poly', C = c)\n",
        "    \n",
        "    \n",
        "    svc_polynomial.fit(xTrain, yTrain) \n",
        "    \n",
        "    # Find the prediction and accuracy on the training set.\n",
        "    Yhat_svc_polynomial_train = svc_polynomial.predict(xTrain)\n",
        "    acc_train = np.mean(Yhat_svc_polynomial_train == yTrain)\n",
        "    acc_train_svm_poly.append(acc_train)\n",
        "    print('Accuracy = {0:f}'.format(acc_train))\n",
        "    \n",
        "    # Find the prediction and accuracy on the test set.\n",
        "    Yhat_svc_polynomial_test = svc_polynomial.predict(xVal)\n",
        "    acc_test = np.mean(Yhat_svc_polynomial_test == yVal)\n",
        "    acc_test_svm_poly.append(acc_test)\n",
        "    print('Accuracy = {0:f}'.format(acc_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7tXih9H6ETj"
      },
      "outputs": [],
      "source": [
        "c_svm_poly = [0.0001,0.001,0.01,0.1,1,10,100]\n",
        "\n",
        "\n",
        "for c in c_svm_poly:\n",
        "    svm_polynomial(c)\n",
        "\n",
        "plt.plot(c_svm_poly, acc_train_svm_poly,'.-',color='red')\n",
        "plt.plot(c_svm_poly, acc_test_svm_poly,'.-',color='orange')\n",
        "plt.xlabel('c')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(\"Plot of accuracy vs c for training and test data\")\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNftXFuV6Hw-"
      },
      "outputs": [],
      "source": [
        "#Try more values of c for polynomial kernel.\n",
        "c_svm_poly_extended=[200,500,1000]\n",
        "for c in c_svm_poly_extended:\n",
        "    svm_polynomial(c)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "svclassifier = SVC(kernel='poly', degree=8)\n",
        "svclassifier.fit(xTrain, yTrain)"
      ],
      "metadata": {
        "id": "he_uCBpAhdc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = svclassifier.predict(xVal)"
      ],
      "metadata": {
        "id": "aYw2SIhPikeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(yVal, y_pred))\n",
        "print(classification_report(yVal, y_pred))"
      ],
      "metadata": {
        "id": "B1JM8GmViztr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_J6D_C2MScq"
      },
      "source": [
        "### SVM RBF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74scM-A1MY3K"
      },
      "outputs": [],
      "source": [
        "def svm_rbf(c, g):\n",
        "    svc_rbf = svm.SVC(probability = False, kernel = 'rbf', C = c, gamma = g)\n",
        "    \n",
        "    # Fit the classifier on the training set.\n",
        "    svc_rbf.fit(xTrain, yTrain) \n",
        "    \n",
        "    # Find the prediction and accuracy on the training set.\n",
        "    Yhat_svc_rbf_train = svc_rbf.predict(xTrain)\n",
        "    acc = np.mean(Yhat_svc_rbf_train == yTrain)\n",
        "    print('Train Accuracy = {0:f}'.format(acc))\n",
        "    acc_train_svm_rbf.append(acc)\n",
        "    \n",
        "    # Find the prediction and accuracy on the test set.\n",
        "    Yhat_svc_rbf_test = svc_rbf.predict(xVal)\n",
        "    acc = np.mean(Yhat_svc_rbf_test == yVal)\n",
        "    print('Test Accuracy = {0:f}'.format(acc))\n",
        "    acc_test_svm_rbf.append(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHJcyBxBMbUr"
      },
      "outputs": [],
      "source": [
        "acc_train_svm_rbf= []\n",
        "acc_test_svm_rbf = []\n",
        "c_svm_rbf = [0.0001,0.001,0.01,0.1,1,10,100]\n",
        "\n",
        "for c in c_svm_rbf:\n",
        "     svm_rbf(c, 'auto')\n",
        "    \n",
        "plt.plot(c_svm_rbf, acc_train_svm_rbf,'.-',color='red')\n",
        "plt.plot(c_svm_rbf, acc_test_svm_rbf,'.-',color='orange')\n",
        "plt.xlabel('c')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(\"Plot of accuracy vs c for training and test data\")\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svclassifier = SVC(kernel='rbf')\n",
        "svclassifier.fit(xTrain, yTrain)\n",
        "y_pred = svclassifier.predict(xVal)\n",
        "print(confusion_matrix(yVal, y_pred))\n",
        "print(classification_report(yVal, y_pred))"
      ],
      "metadata": {
        "id": "N8-xrQJtjNJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G6MGHIl2bvJ"
      },
      "source": [
        "## Devolping DCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLA3nC43esgx"
      },
      "outputs": [],
      "source": [
        "#Normalize train/test\n",
        "x_train = x_train/225\n",
        "x_test = x_test/255\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctpCAqAle5AZ"
      },
      "outputs": [],
      "source": [
        "#converting Categorical to numercial\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_cat_train = to_categorical(y_train,10)\n",
        "y_cat_test = to_categorical(y_test,10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WS-BgOnJUxCq"
      },
      "source": [
        "### Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxMPKsWUe9G1"
      },
      "outputs": [],
      "source": [
        "#Building Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n",
        "model = Sequential()\n",
        "\n",
        "## FIRST SET OF LAYERS\n",
        "\n",
        "# CONVOLUTIONAL LAYER\n",
        "model.add(Conv2D(filters=32, kernel_size=(4,4),input_shape=(32, 32, 3), activation='relu',))\n",
        "# POOLING LAYER\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "## SECOND SET OF LAYERS\n",
        "\n",
        "# CONVOLUTIONAL LAYER\n",
        "model.add(Conv2D(filters=32, kernel_size=(4,4),input_shape=(32, 32, 3), activation='relu',))\n",
        "# POOLING LAYER\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "# FLATTEN IMAGES FROM 28 by 28 to 764 BEFORE FINAL LAYER\n",
        "model.add(Flatten())\n",
        "\n",
        "# 256 NEURONS IN DENSE HIDDEN LAYER (WE CAN CHANGE THIS NUMBER OF NEURONS)\n",
        "model.add(Dense(256, activation='relu'))\n",
        "\n",
        "# LAST LAYER IS THE CLASSIFIER, THUS 10 POSSIBLE CLASSES\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjeNilbQfFB9"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBmjAGk3fHxW"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss',patience=3)\n",
        "model.fit(x_train,y_cat_train,epochs=15,validation_data=(x_test,y_cat_test),callbacks=[early_stop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__cTCyNHf6Ug"
      },
      "outputs": [],
      "source": [
        "#Calculating Lossses\n",
        "losses = pd.DataFrame(model.history.history)\n",
        "losses.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHJLnMkFgB5m"
      },
      "outputs": [],
      "source": [
        "losses[['accuracy','val_accuracy']].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbTfv1NMgHlj"
      },
      "outputs": [],
      "source": [
        "losses[['loss','val_loss']].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oePX-dggKs2"
      },
      "outputs": [],
      "source": [
        "model.metrics_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5y5cB4kMgQu4"
      },
      "outputs": [],
      "source": [
        "print(model.metrics_names)\n",
        "print(model.evaluate(x_test,y_cat_test,verbose=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7dc_EnrgS_O"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "predict_x=model.predict(x_test) \n",
        "classes_x=np.argmax(predict_x,axis=1)\n",
        "#predictions = model.predict_classes(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "na1M8QvtgWlm"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test,classes_x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGIRqdS6gbGP"
      },
      "outputs": [],
      "source": [
        "confusion_matrix(y_test,classes_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CfLLrrlgeoS"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(confusion_matrix(y_test,classes_x),annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4anwMxfYgwS_"
      },
      "outputs": [],
      "source": [
        "#predicting image\n",
        "my_image = x_test[16]\n",
        "plt.imshow(my_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VA2gjo_sU00C"
      },
      "source": [
        "### Rsnet 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ty17qnOrg0gz"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32 \n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arroLG8BU7mB"
      },
      "outputs": [],
      "source": [
        "#Matplotlib config\n",
        "plt.rc('image', cmap='gray')\n",
        "plt.rc('grid', linewidth=0)\n",
        "plt.rc('xtick', top=False, bottom=False, labelsize='large')\n",
        "plt.rc('ytick', left=False, right=False, labelsize='large')\n",
        "plt.rc('axes', facecolor='F8F8F8', titlesize=\"large\", edgecolor='white')\n",
        "plt.rc('text', color='a8151a')\n",
        "plt.rc('figure', facecolor='F0F0F0')# Matplotlib fonts\n",
        "MATPLOTLIB_FONT_DIR = os.path.join(os.path.dirname(plt.__file__), \"mpl-data/fonts/ttf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaZhXtq_U-Lh"
      },
      "outputs": [],
      "source": [
        "# utility to display a row of digits with their predictions\n",
        "def display_images(digits, predictions, labels, title):\n",
        "\n",
        "  n = 10\n",
        "\n",
        "  indexes = np.random.choice(len(predictions), size=n)\n",
        "  n_digits = digits[indexes]\n",
        "  n_predictions = predictions[indexes]\n",
        "  n_predictions = n_predictions.reshape((n,))\n",
        "  n_labels = labels[indexes]\n",
        " \n",
        "  fig = plt.figure(figsize=(20, 4))\n",
        "  plt.title(title)\n",
        "  plt.yticks([])\n",
        "  plt.xticks([])\n",
        "\n",
        "  for i in range(10):\n",
        "    ax = fig.add_subplot(1, 10, i+1)\n",
        "    class_index = n_predictions[i]\n",
        "    \n",
        "    plt.xlabel(classes[class_index])\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(n_digits[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1z0YWzr5VCtI"
      },
      "outputs": [],
      "source": [
        "# utility to display training and validation curves\n",
        "def plot_metrics(metric_name, title, ylim=5):\n",
        "  plt.title(title)\n",
        "  plt.ylim(0,ylim)\n",
        "  plt.plot(history.history[metric_name],color='blue',label=metric_name)\n",
        "  plt.plot(history.history['val_' + metric_name],color='green',label='val_' + metric_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T76jgvIdVCp-"
      },
      "outputs": [],
      "source": [
        "#Loading and Preprocessing Data\n",
        "(training_images, training_labels) , (validation_images, validation_labels) = tf.keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeAwW3kkVCmI"
      },
      "outputs": [],
      "source": [
        "#Visualization of Dataset\n",
        "display_images(training_images, training_labels, training_labels, \"Training Data\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znL5k8F7VJrP"
      },
      "outputs": [],
      "source": [
        "display_images(validation_images, validation_labels, validation_labels, \"Training Data\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khLkVoa-VL_O"
      },
      "outputs": [],
      "source": [
        "# Preprocess dataset\n",
        "def preprocess_image_input(input_images):\n",
        "  input_images = input_images.astype('float32')\n",
        "  output_ims = tf.keras.applications.resnet50.preprocess_input(input_images)\n",
        "  return output_ims"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76RDrOYkVM38"
      },
      "outputs": [],
      "source": [
        "train_X = preprocess_image_input(training_images)\n",
        "valid_X = preprocess_image_input(validation_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKPVKwQmVQWa"
      },
      "outputs": [],
      "source": [
        "# Defining Network\n",
        "#Feature Extraction is performed by ResNet50 pretrained on imagenet weights. Input size is 224 x 224.\n",
        "def feature_extractor(inputs):\n",
        "\n",
        "  feature_extractor = tf.keras.applications.resnet.ResNet50(input_shape=(224, 224, 3),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')(inputs)\n",
        "  return feature_extractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q56Mk7BAVSie"
      },
      "outputs": [],
      "source": [
        "#Defines final dense layers and subsequent softmax layer for classification.\n",
        "def classifier(inputs):\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"classification\")(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAHC8uHWVSer"
      },
      "outputs": [],
      "source": [
        "# Since input image size is (32 x 32), first upsample the image by factor of (7x7) to transform it to (224 x 224) Connect the feature extraction and \"classifier\" layers to build the model.\n",
        "def final_model(inputs):\n",
        "\n",
        "    resize = tf.keras.layers.UpSampling2D(size=(7,7))(inputs)\n",
        "\n",
        "    resnet_feature_extractor = feature_extractor(resize)\n",
        "    classification_output = classifier(resnet_feature_extractor)\n",
        "\n",
        "    return classification_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFCdBj2YVSbi"
      },
      "outputs": [],
      "source": [
        "# Define the model and compile it. Use Stochastic Gradient Descent as the optimizer. Use Sparse Categorical CrossEntropy as the loss function.\n",
        "\n",
        "def define_compile_model():\n",
        "  inputs = tf.keras.layers.Input(shape=(32,32,3))\n",
        "  \n",
        "  classification_output = final_model(inputs) \n",
        "  model = tf.keras.Model(inputs=inputs, outputs = classification_output)\n",
        " \n",
        "  model.compile(optimizer='SGD', \n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics = ['accuracy'])\n",
        "  \n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiqjeK3wVSXO"
      },
      "outputs": [],
      "source": [
        "model = define_compile_model()\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4-sA_S2vVbXY"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "EPOCHS = 3\n",
        "history = model.fit(train_X, training_labels, epochs=EPOCHS, validation_data = (valid_X, validation_labels), batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBSthuK_VdZ7"
      },
      "outputs": [],
      "source": [
        "# Evaluate the Model\n",
        "loss, accuracy = model.evaluate(valid_X, validation_labels, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRho04BlVdW9"
      },
      "outputs": [],
      "source": [
        "# Printing Accuracy\n",
        "print(\"Accuracy\", accuracy*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHNabRVEVqiH"
      },
      "source": [
        "#### In the upper cell we can see the accuray of our trained moded on CIFAR-10 dataset using Resent 50 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNLHi3HaVdSk"
      },
      "outputs": [],
      "source": [
        "# Plot Loss and Accuracy Curves\n",
        "plot_metrics(\"loss\", \"Loss\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeD3TP5eVkEp"
      },
      "outputs": [],
      "source": [
        "plot_metrics(\"accuracy\", \"Accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gG4Tv26EVmgL"
      },
      "outputs": [],
      "source": [
        "# Visualize predictions\n",
        "probabilities = model.predict(valid_X, batch_size=64)\n",
        "probabilities = np.argmax(probabilities, axis = 1)\n",
        "\n",
        "display_images(validation_images, probabilities, validation_labels, \"Bad predictions indicated in red.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Cifar_Comparision_KNN_SVM_CNN_RSNET.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}